# Implementation Plan: Phase IV - Local Kubernetes Deployment

**Branch**: `001-k8s-deployment` | **Date**: 2025-12-24 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/001-k8s-deployment/spec.md`

**Note**: This document outlines the technical implementation strategy for deploying the Todo Chatbot to local Kubernetes (Minikube) using AI-assisted DevOps tools.

## Summary

Deploy the Phase III Todo Chatbot (Next.js frontend + FastAPI backend) to a local Kubernetes cluster using Minikube. The implementation follows an AI-first DevOps approach, utilizing Gordon for Docker operations, kubectl-ai for Kubernetes manifest generation, and kagent for cluster optimization. The deployment will use Helm charts for templated resource management, ensuring reproducibility and configurability.

**Primary Requirement**: Containerize both applications with multi-stage Docker builds, generate Helm charts for Kubernetes deployment, deploy to Minikube cluster in isolated `todo-app` namespace, and validate AI DevOps tool effectiveness.

**Technical Approach**: Six-phase implementation following constitution gates: Setup (tools verification) → Containerization (Docker images) → Helm Charts (K8s templates) → Deployment (Minikube cluster) → Optimization (HPA + resources) → Documentation (complete artifacts and PHRs).

## Technical Context

**Language/Version**:
- Frontend: TypeScript 5, Node.js 18+, Next.js 16.0.10, React 19.2.1
- Backend: Python 3.11+, FastAPI 0.115.6, SQLAlchemy 2.0.36

**Primary Dependencies**:
- Frontend: next@16.0.10, react@19.2.1, better-auth@1.4.7, tailwindcss@4, radix-ui components
- Backend: fastapi@0.115.6, uvicorn@0.34.0, sqlalchemy@2.0.36, psycopg2-binary@2.9.10, openai>=1.0.0

**Storage**: PostgreSQL (accessible from Kubernetes cluster - either external service or deployed within cluster)

**Testing**:
- Frontend: Next.js built-in testing capabilities
- Backend: pytest@7.0.0, pytest-asyncio@0.21.0, httpx@0.24.0

**Target Platform**:
- Development: Minikube (local Kubernetes cluster on Docker Desktop)
- Containers: Alpine Linux-based (node:18-alpine, python:3.11-alpine)
- Container Runtime: Docker Desktop 4.53+ with Gordon enabled

**Project Type**: Web application (separate frontend and backend services)

**Performance Goals**:
- Docker image build time: < 5 minutes per image
- Helm chart installation: < 2 minutes
- Pod startup time: < 30 seconds
- Frontend UI load time: < 3 seconds
- Backend API response time: < 500ms (p95)

**Constraints**:
- Image sizes: Frontend < 200MB, Backend < 150MB
- Resource limits: Backend (250m-500m CPU, 256Mi-512Mi RAM), Frontend (100m-200m CPU, 128Mi-256Mi RAM)
- Minimum 2 replicas for each service
- All artifacts generated by AI tools (Gordon, kubectl-ai, kagent) per Agentic First principle
- Zero hardcoded secrets - ConfigMaps/Secrets only

**Scale/Scope**:
- Target: Local development/testing deployment
- Replicas: 2 frontend pods, 2-10 backend pods (HPA enabled)
- Expected load: Development testing (< 100 concurrent users)
- Deployment scope: Single Minikube cluster, single namespace (`todo-app`)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Core Principles Compliance

✅ **I. Agentic First**
- All Dockerfiles generated by Gordon (fallback: Claude Code → Manual)
- All Helm charts generated by kubectl-ai (fallback: Claude Code → Manual)
- All cluster operations use kagent for analysis (fallback: kubectl commands)
- Every AI tool interaction documented in PHR format
- Manual coding prohibited without documented fallback justification

✅ **II. Spec Driven**
- Specification complete (`specs/001-k8s-deployment/spec.md`)
- Planning document (this file) follows `/specify` → `/plan` workflow
- Implementation will follow `/plan` → `/tasks` → `/implement` sequence
- All changes reference specification requirements (FR-001 through FR-020)

✅ **III. Tool Native**
- Gordon primary for Docker operations (command: `docker ai '<prompt>'`)
- kubectl-ai primary for K8s manifests (command: `kubectl-ai '<prompt>'`)
- kagent primary for cluster optimization (command: `kagent '<prompt>'`)
- Fallback order strictly enforced and documented
- Traditional CLI commands as last resort only

✅ **IV. Documentation First**
- All AI interactions logged with prompt/tool/response/iterations/decision/rationale
- PHRs created for each phase completion
- ADRs created for significant architectural decisions
- Iteration logs capture refinement reasoning

### Architectural Constraints Compliance

✅ **Containerization**
- Multi-stage builds mandatory (enforced via Gordon prompts)
- Alpine-based images required (node:18-alpine, python:3.11-alpine)
- Health checks implemented (`/api/health` frontend, `/health` backend)
- No hardcoded secrets (ConfigMaps/Secrets only)
- Layer caching optimized (dependency files copied before source code)
- No root user in production containers
- No `:latest` tags (versioned: `v1.0.0`)
- .dockerignore files required

✅ **Kubernetes Deployment**
- Helm charts mandatory (generated via kubectl-ai)
- Resource limits defined (per constitution specifications)
- Minimum 2 replicas (frontend: 2, backend: 2-10 with HPA)
- Namespace isolation (`todo-app` namespace)
- Services use ClusterIP (exception: frontend NodePort for Minikube access)
- ConfigMaps for configuration
- Liveness and readiness probes mandatory
- Rolling update strategy
- HPA for scalable services

✅ **AI DevOps Integration**
- Gordon attempted first for Docker operations
- kubectl-ai for Kubernetes manifest generation
- kagent for cluster optimization and analysis
- All interactions documented per template

### Security Constraints Compliance

✅ **Secrets Management**
- No secrets in version control (.gitignore includes .env, secrets/)
- Kubernetes Secrets for database credentials and API keys
- Base64 encoding enforced
- Rotation procedure documented

✅ **Image Security**
- Images scanned with hadolint before deployment
- Official base images only (Docker Hub: node:18-alpine, python:3.11-alpine)
- Run as non-root user (USER directive in Dockerfile)
- Minimize exposed ports (only required service ports)

### Quality Constraints Compliance

✅ **Testing Requirements**
- Pre-deployment: Local container testing, health endpoint verification, integration testing
- Post-deployment: Smoke tests after Helm install, end-to-end functionality, resource monitoring

✅ **Validation Gates**
- Dockerfile: hadolint linting required
- Helm charts: `helm lint` and `helm template` validation required
- Kubernetes: All pods Running, services have endpoints, no CrashLoopBackOff

✅ **Performance Requirements**
- Docker build < 5 minutes ✓
- Helm install < 2 minutes ✓
- Pod startup < 30 seconds ✓
- Resource limits enforced ✓

### Workflow Constraints Compliance

✅ **Phase Gates**
- Phase 1: Setup (tools + Minikube) → Exit: All tools verified, cluster running
- Phase 2: Containerization → Exit: Images built, tested, health checks verified
- Phase 3: Helm Charts → Exit: Charts linted, templates rendered
- Phase 4: Deployment → Exit: Pods Running, services accessible
- Phase 5: Optimization → Exit: HPA configured, resources optimized
- Phase 6: Documentation → Exit: All artifacts complete, AI interactions logged

✅ **Iteration Rules**
- Max 5 iterations per task
- Document iteration number, reason, modified approach, outcome, lessons learned

✅ **Approval Gates**
- Technical review: Human approval before deployment
- Documentation review: Human approval after documentation complete

**GATE RESULT**: ✅ PASS - All constitution requirements satisfied. Proceed to Phase 0 research.

## Project Structure

### Documentation (this feature)

```text
specs/001-k8s-deployment/
├── spec.md              # Feature specification (complete)
├── plan.md              # This file (/sp.plan command output)
├── research.md          # Phase 0 output (Docker/K8s/Helm best practices)
├── data-model.md        # Phase 1 output (Deployment entities and configurations)
├── quickstart.md        # Phase 1 output (Step-by-step deployment guide)
├── contracts/           # Phase 1 output (Dockerfile specs, Helm values schemas)
│   ├── backend-dockerfile.spec.md
│   ├── frontend-dockerfile.spec.md
│   ├── backend-helm-values.yaml
│   └── frontend-helm-values.yaml
├── checklists/
│   └── requirements.md  # Spec quality validation (complete)
└── tasks.md             # Phase 2 output (/sp.tasks command - NOT created by /sp.plan)
```

### Source Code (repository root)

```text
# Web application structure (frontend + backend detected)
backend/
├── agents/              # AI agent system
│   ├── main_agent.py
│   ├── agent_config.py
│   └── skills/
├── config/              # Application settings
├── db/                  # Database utilities
├── mcp_tools/           # MCP tool implementations
├── routes/              # API routes (chat, tasks)
├── utils/               # Utilities (error handling, monitoring)
├── models.py            # SQLAlchemy models
├── service.py           # Task CRUD API
├── database.py          # DB connection management
├── main.py              # FastAPI application entry
├── limiter.py           # Rate limiting
├── requirements.txt     # Python dependencies
├── .env                 # Environment variables (gitignored)
├── Dockerfile           # To be generated by Gordon (Phase 2)
├── .dockerignore        # To be created (Phase 2)
└── tests/               # pytest tests

frontend/
├── app/                 # Next.js app directory
│   ├── actions/         # Server actions
│   ├── api/             # API routes (better-auth)
│   ├── signin/          # Sign-in page
│   ├── signup/          # Sign-up page
│   ├── todo/            # Todo page (protected)
│   ├── layout.tsx       # Root layout
│   ├── page.tsx         # Landing page
│   └── globals.css      # Global styles
├── components/          # React components
│   ├── chat/            # Chat UI
│   ├── ui/              # Reusable UI components
│   └── todo components  # Task management
├── lib/                 # Utilities (auth.ts)
├── types/               # TypeScript types
├── package.json         # Dependencies
├── .env                 # Environment variables (gitignored)
├── Dockerfile           # To be generated by Gordon (Phase 2)
├── .dockerignore        # To be created (Phase 2)
└── next.config.ts       # Next.js configuration

# Kubernetes deployment artifacts (to be generated)
helm-charts/
├── todo-backend/        # Backend Helm chart (kubectl-ai generated)
│   ├── Chart.yaml
│   ├── values.yaml
│   └── templates/
│       ├── deployment.yaml
│       ├── service.yaml
│       ├── configmap.yaml
│       ├── secrets.yaml
│       └── hpa.yaml
└── todo-frontend/       # Frontend Helm chart (kubectl-ai generated)
    ├── Chart.yaml
    ├── values.yaml
    └── templates/
        ├── deployment.yaml
        ├── service.yaml
        ├── configmap.yaml
        └── hpa.yaml (optional)

# AI DevOps documentation
docs/
├── ai-devops/
│   ├── gordon-interactions.md    # Gordon command history
│   ├── kubectl-ai-interactions.md # kubectl-ai command history
│   └── kagent-interactions.md    # kagent command history
└── deployment-runbook.md          # Complete deployment procedure
```

**Structure Decision**: Web application architecture selected due to presence of separate `frontend/` and `backend/` directories. Both services will be containerized independently and deployed as separate Kubernetes Deployments with dedicated Services. Helm charts will be generated per-service for maximum flexibility and independent scaling. Project maintains existing directory structure; only adds Dockerfiles, .dockerignore, and helm-charts/ at repository root.

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

**No violations detected.** All implementation choices align with constitution requirements. The use of multiple tools (Gordon, kubectl-ai, kagent) is mandated by Tool Native principle, not complexity addition. Two separate services (frontend/backend) represent natural application architecture, not unnecessary complexity.

---

## Phase 0: Research & Technology Selection

**Objective**: Research Docker containerization best practices, Kubernetes deployment patterns, Helm chart structure, and AI DevOps tool capabilities to resolve any ambiguities and establish concrete implementation approach.

### Research Tasks

1. **Docker Multi-Stage Build Patterns for Next.js**
   - Research optimal Next.js production Dockerfile structure
   - Investigate standalone output vs static export for containerization
   - Identify minimal runtime requirements (node vs nginx serving)
   - Document layer caching strategies for npm dependencies

2. **Docker Multi-Stage Build Patterns for FastAPI**
   - Research Python Alpine-based production Dockerfile patterns
   - Investigate poetry vs pip vs uv for dependency management
   - Identify minimal runtime requirements and security best practices
   - Document health check endpoint implementation patterns

3. **Helm Chart Best Practices**
   - Research Helm chart structure and templating patterns
   - Investigate values.yaml organization for environment-specific configuration
   - Document resource limit calculation methodologies
   - Identify probe configuration best practices (initial delay, timeout, failure threshold)

4. **Kubernetes Service Discovery and Networking**
   - Research ClusterIP vs NodePort for local Minikube access
   - Investigate DNS-based service discovery patterns (`http://service-name:port`)
   - Document ConfigMap vs Secret usage for configuration management
   - Identify best practices for database connection from K8s pods

5. **AI DevOps Tool Capabilities**
   - Research Gordon command patterns and prompt engineering best practices
   - Investigate kubectl-ai capabilities and command syntax
   - Document kagent analysis features and optimization recommendations
   - Identify fallback strategies when AI tools produce invalid output

### Research Output

**File**: `research.md`

**Structure**:
```markdown
# Research: Phase IV Kubernetes Deployment

## Docker Containerization

### Next.js Dockerfile Pattern
- **Decision**: Use node:18-alpine for build stage, standalone output mode, node for runtime
- **Rationale**: Standalone output includes minimal dependencies, faster startup than static export + nginx
- **Alternatives Considered**: Static export + nginx (rejected: requires separate web server, larger image)
- **Implementation**: Multi-stage build with npm ci, next build, copy .next/standalone

### FastAPI Dockerfile Pattern
- **Decision**: Use python:3.11-alpine for both build and runtime, single-user mode, uvicorn direct
- **Rationale**: FastAPI lightweight enough for single-stage optimization, Alpine minimizes attack surface
- **Alternatives Considered**: Debian-slim (rejected: larger image size), multi-stage (not needed for Python)
- **Implementation**: Install dependencies, copy source, run as non-root user, expose health endpoint

## Helm Chart Architecture

### Chart Structure Decision
- **Decision**: Separate charts for frontend and backend with shared configuration via parent chart
- **Rationale**: Independent versioning and scaling, simpler CI/CD integration
- **Alternatives Considered**: Umbrella chart only (rejected: less flexible), monolithic chart (rejected: tight coupling)
- **Implementation**: Two standalone charts in `helm-charts/` directory

### Resource Limit Calculation
- **Decision**: Use constitution-specified limits as baseline, adjust via kagent recommendations
- **Rationale**: Constitution provides production-ready starting point based on typical workloads
- **Monitoring**: Track actual usage via `kubectl top pods`, adjust if needed

## Kubernetes Networking

### Service Exposure Strategy
- **Decision**: Frontend NodePort (30000-32767), Backend ClusterIP, DNS-based discovery
- **Rationale**: NodePort enables Minikube access without ingress, ClusterIP for internal backend
- **Implementation**: Frontend Service type=NodePort, backend Service type=ClusterIP on port 8000

### Configuration Management
- **Decision**: ConfigMaps for non-sensitive config, Secrets for database credentials and API keys
- **Rationale**: Follows Kubernetes security best practices, enables runtime configuration updates
- **Implementation**: ConfigMaps for URLs/ports, Secrets for DATABASE_URL and OPENAI_API_KEY

## AI DevOps Tool Usage

### Gordon Prompt Patterns
- **Effective Prompts**:
  - "Create production-ready Dockerfile for Next.js 16 app using standalone output and Alpine base"
  - "Generate optimized Dockerfile for FastAPI backend with health checks and non-root user"
- **Fallback Triggers**: Syntax errors, missing health checks, root user, latest tags

### kubectl-ai Command Patterns
- **Effective Prompts**:
  - "Create Helm chart for backend API with 2 replicas and resource limits 500m CPU 512Mi memory"
  - "Generate frontend deployment with NodePort service and ConfigMap for backend URL"
- **Fallback Triggers**: Invalid YAML syntax, missing required fields, incorrect resource format

### kagent Analysis Capabilities
- **Commands**:
  - "Analyze cluster health and resource utilization"
  - "Optimize resource allocation for todo-app namespace"
  - "Check why pods are failing in todo-app namespace"
- **Use Cases**: Post-deployment optimization, troubleshooting, resource right-sizing

## Database Connectivity

### PostgreSQL Access from Kubernetes
- **Decision**: Use external PostgreSQL service with connection via Kubernetes Secret
- **Rationale**: Existing database from Phase III, avoids data migration, simpler initial deployment
- **Implementation**: DATABASE_URL in Secret, mounted as environment variable in backend pods
- **Alternative**: Deploy PostgreSQL in K8s cluster (future enhancement if needed)
```

---

## Phase 1: Design & Contracts

**Prerequisite**: Phase 0 research.md complete

**Objective**: Define deployment entity model, generate Dockerfile specifications, create Helm chart contracts, and produce quickstart deployment guide.

### Deployment Data Model

**File**: `data-model.md`

**Entities**:

1. **Docker Image (Frontend)**
   - **Attributes**: name (`todo-frontend`), tag (`v1.0.0`), base image (`node:18-alpine`), size target (`< 200MB`)
   - **Build Stages**: dependencies (npm ci), build (next build), production (node server)
   - **Health Check**: `/api/health` endpoint, 30s interval
   - **Environment Variables**: NEXT_PUBLIC_API_URL, NODE_ENV
   - **Validation**: hadolint score > 0, no DL3xxx errors, non-root user

2. **Docker Image (Backend)**
   - **Attributes**: name (`todo-backend`), tag (`v1.0.0`), base image (`python:3.11-alpine`), size target (`< 150MB`)
   - **Build Process**: Install requirements, copy source, create non-root user
   - **Health Check**: `/health` endpoint, 30s interval
   - **Environment Variables**: DATABASE_URL, OPENAI_API_KEY, PORT
   - **Validation**: hadolint score > 0, no DL3xxx errors, non-root user

3. **Helm Chart (Frontend)**
   - **Chart Metadata**: name (`todo-frontend`), version (`0.1.0`), appVersion (`1.0.0`)
   - **Templates**: Deployment (2 replicas), Service (NodePort), ConfigMap (API URL)
   - **Values**: image.repository, image.tag, replicaCount, resources (requests/limits)
   - **Probes**: liveness (`/api/health`), readiness (`/api/health`), initialDelaySeconds (10)
   - **Resource Limits**: CPU 100m-200m, Memory 128Mi-256Mi

4. **Helm Chart (Backend)**
   - **Chart Metadata**: name (`todo-backend`), version (`0.1.0`), appVersion (`1.0.0`)
   - **Templates**: Deployment (2 replicas), Service (ClusterIP), ConfigMap (config), Secret (credentials), HPA (2-10 replicas)
   - **Values**: image.repository, image.tag, replicaCount, resources, autoscaling settings
   - **Probes**: liveness (`/health`), readiness (`/health`), initialDelaySeconds (15)
   - **Resource Limits**: CPU 250m-500m, Memory 256Mi-512Mi

5. **Kubernetes Deployment (Frontend)**
   - **Replicas**: 2 (no autoscaling - static frontend)
   - **Image Pull Policy**: IfNotPresent (local Minikube images)
   - **Restart Policy**: Always
   - **Update Strategy**: RollingUpdate (maxSurge: 1, maxUnavailable: 0)
   - **Labels**: app=todo-frontend, version=v1.0.0, component=ui

6. **Kubernetes Deployment (Backend)**
   - **Replicas**: 2-10 (HorizontalPodAutoscaler enabled)
   - **Image Pull Policy**: IfNotPresent
   - **Restart Policy**: Always
   - **Update Strategy**: RollingUpdate (maxSurge: 2, maxUnavailable: 1)
   - **Labels**: app=todo-backend, version=v1.0.0, component=api

7. **Kubernetes Service (Frontend)**
   - **Type**: NodePort
   - **Port**: 80 (service) → 3000 (container) → 30080 (nodePort)
   - **Selector**: app=todo-frontend
   - **Session Affinity**: ClientIP (for consistent frontend experience)

8. **Kubernetes Service (Backend)**
   - **Type**: ClusterIP
   - **Port**: 8000 (service) → 8000 (container)
   - **Selector**: app=todo-backend
   - **Internal DNS**: `todo-backend.todo-app.svc.cluster.local`

9. **ConfigMap (Frontend)**
   - **Data**: `NEXT_PUBLIC_API_URL=http://todo-backend:8000`, `NODE_ENV=production`

10. **ConfigMap (Backend)**
    - **Data**: `PORT=8000`, `LOG_LEVEL=info`, `CORS_ORIGINS=*`

11. **Secret (Backend)**
    - **Data**: `DATABASE_URL` (base64 encoded PostgreSQL connection string), `OPENAI_API_KEY` (base64 encoded API key)
    - **Type**: Opaque
    - **Immutable**: false (allows rotation)

12. **HorizontalPodAutoscaler (Backend)**
    - **Min Replicas**: 2
    - **Max Replicas**: 10
    - **Target Metrics**: CPU utilization 70%, Memory utilization 80%
    - **Behavior**: Scale up aggressively (3 pods per minute), scale down conservatively (1 pod per 5 minutes)

### Deployment Contracts

**Directory**: `contracts/`

**Files**:

1. **`backend-dockerfile.spec.md`**
```markdown
# Backend Dockerfile Specification

## Base Requirements
- Base Image: `python:3.11-alpine`
- Final Image Size: < 150MB
- Non-root user: `appuser` (UID 1000)
- Working Directory: `/app`

## Build Instructions
1. Install system dependencies: `gcc musl-dev postgresql-dev`
2. Copy `requirements.txt`
3. Install Python dependencies: `pip install --no-cache-dir -r requirements.txt`
4. Copy application source code
5. Create non-root user
6. Set ownership and permissions

## Runtime Configuration
- Port: 8000
- Command: `uvicorn main:app --host 0.0.0.0 --port 8000`
- Health Check: `HEALTHCHECK CMD curl --fail http://localhost:8000/health || exit 1`
- Environment Variables: DATABASE_URL, OPENAI_API_KEY, PORT

## Validation Criteria
- hadolint passes with zero errors
- Image builds in < 5 minutes
- Container starts and responds to /health within 10 seconds
- Non-root user verified with `docker exec <container> whoami`
```

2. **`frontend-dockerfile.spec.md`**
```markdown
# Frontend Dockerfile Specification

## Base Requirements
- Build Image: `node:18-alpine`
- Runtime Image: `node:18-alpine`
- Final Image Size: < 200MB
- Non-root user: `nodejs` (pre-existing in node:alpine)
- Working Directory: `/app`

## Build Instructions
1. Copy `package.json` and `package-lock.json`
2. Run `npm ci --only=production`
3. Copy application source
4. Build: `npm run build`
5. Use Next.js standalone output

## Runtime Configuration
- Port: 3000
- Command: `node server.js` (standalone output)
- Health Check: `HEALTHCHECK CMD wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1`
- Environment Variables: NEXT_PUBLIC_API_URL, NODE_ENV=production

## Validation Criteria
- hadolint passes with zero errors
- Image builds in < 5 minutes
- Container starts and serves UI within 10 seconds
- Standalone output verified in .next/standalone/
```

3. **`backend-helm-values.yaml`** (Schema/Template)
```yaml
# Backend Helm Chart Values Schema

replicaCount: 2

image:
  repository: todo-backend
  tag: v1.0.0
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8000
  targetPort: 8000

resources:
  requests:
    cpu: 250m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi

probes:
  liveness:
    path: /health
    initialDelaySeconds: 15
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readiness:
    path: /health
    initialDelaySeconds: 10
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

config:
  port: "8000"
  logLevel: "info"
  corsOrigins: "*"

secrets:
  databaseUrl: "<base64-encoded-postgres-url>"
  openaiApiKey: "<base64-encoded-api-key>"
```

4. **`frontend-helm-values.yaml`** (Schema/Template)
```yaml
# Frontend Helm Chart Values Schema

replicaCount: 2

image:
  repository: todo-frontend
  tag: v1.0.0
  pullPolicy: IfNotPresent

service:
  type: NodePort
  port: 80
  targetPort: 3000
  nodePort: 30080

resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 200m
    memory: 256Mi

probes:
  liveness:
    path: /api/health
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readiness:
    path: /api/health
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3

config:
  apiUrl: "http://todo-backend:8000"
  nodeEnv: "production"
```

### Quickstart Guide

**File**: `quickstart.md`

```markdown
# Quickstart: Phase IV Kubernetes Deployment

## Prerequisites

- Docker Desktop 4.53+ with Gordon enabled
- Minikube installed and running
- kubectl configured for Minikube context
- kubectl-ai installed
- kagent installed
- Helm 3+ installed

## Step 1: Verify Environment

```bash
# Verify Docker and Gordon
docker --version
docker ai 'What can you do?'

# Verify Minikube
minikube version
minikube status

# Verify kubectl and AI tools
kubectl version --client
kubectl-ai --version
kagent --version

# Verify Helm
helm version
```

## Step 2: Build Docker Images (Gordon)

```bash
# Navigate to backend
cd backend/

# Use Gordon to create Dockerfile
docker ai 'Create production-ready Dockerfile for FastAPI backend with Alpine base, health checks at /health, and non-root user'

# Review generated Dockerfile
cat Dockerfile

# Build backend image
docker build -t todo-backend:v1.0.0 .

# Test backend locally
docker run -p 8000:8000 -e DATABASE_URL=$DATABASE_URL -e OPENAI_API_KEY=$OPENAI_API_KEY todo-backend:v1.0.0

# Navigate to frontend
cd ../frontend/

# Use Gordon to create Dockerfile
docker ai 'Create production Dockerfile for Next.js 16 app using standalone output mode and Alpine base'

# Review generated Dockerfile
cat Dockerfile

# Build frontend image
docker build -t todo-frontend:v1.0.0 .

# Test frontend locally
docker run -p 3000:3000 -e NEXT_PUBLIC_API_URL=http://localhost:8000 todo-frontend:v1.0.0
```

## Step 3: Generate Helm Charts (kubectl-ai)

```bash
# Create helm-charts directory
mkdir -p helm-charts
cd helm-charts/

# Generate backend Helm chart
kubectl-ai 'Create Helm chart for FastAPI backend with 2 replicas, ClusterIP service on port 8000, ConfigMap for configuration, Secret for database credentials, HPA scaling 2-10 replicas at 70% CPU, resource limits 500m CPU 512Mi memory, health probes at /health'

# Review backend chart
helm lint todo-backend/
helm template todo-backend/ --debug

# Generate frontend Helm chart
kubectl-ai 'Create Helm chart for Next.js frontend with 2 replicas, NodePort service on port 80, ConfigMap for backend URL, resource limits 200m CPU 256Mi memory, health probes at /api/health'

# Review frontend chart
helm lint todo-frontend/
helm template todo-frontend/ --debug
```

## Step 4: Deploy to Minikube

```bash
# Create namespace
kubectl create namespace todo-app

# Create backend secret
kubectl create secret generic backend-secrets \
  --from-literal=DATABASE_URL=$DATABASE_URL \
  --from-literal=OPENAI_API_KEY=$OPENAI_API_KEY \
  -n todo-app

# Install backend chart
helm install todo-backend ./todo-backend/ -n todo-app

# Verify backend deployment
kubectl get pods -n todo-app
kubectl logs -n todo-app -l app=todo-backend

# Install frontend chart
helm install todo-frontend ./todo-frontend/ -n todo-app

# Verify frontend deployment
kubectl get pods -n todo-app
kubectl get svc -n todo-app
```

## Step 5: Access Application

```bash
# Get Minikube URL for frontend
minikube service todo-frontend -n todo-app --url

# Or use kubectl port-forward
kubectl port-forward -n todo-app svc/todo-frontend 8080:80

# Access application at http://localhost:8080 (or Minikube URL)
```

## Step 6: Optimize with kagent

```bash
# Analyze cluster health
kagent 'Analyze cluster health and resource utilization for todo-app namespace'

# Get optimization recommendations
kagent 'Optimize resource allocation for todo-app namespace'

# Monitor autoscaling
kubectl get hpa -n todo-app
kubectl top pods -n todo-app
```

## Troubleshooting

### Pods not starting
```bash
kubectl-ai 'Check why pods are failing in todo-app namespace'
kubectl describe pod <pod-name> -n todo-app
kubectl logs <pod-name> -n todo-app
```

### Service not accessible
```bash
kubectl get ep -n todo-app
kubectl-ai 'Verify service configuration for todo-frontend'
```

### Database connection issues
```bash
kubectl exec -it -n todo-app <backend-pod> -- env | grep DATABASE_URL
kubectl logs -n todo-app -l app=todo-backend | grep -i database
```

## Clean Up

```bash
# Uninstall Helm releases
helm uninstall todo-backend -n todo-app
helm uninstall todo-frontend -n todo-app

# Delete namespace
kubectl delete namespace todo-app
```
```

---

## Phase 2: Completion

**This document represents the completion of the `/sp.plan` command.**

**Deliverables**:
- ✅ Implementation plan (`plan.md`) - This file
- ✅ Technical context filled with concrete details
- ✅ Constitution check completed - ALL GATES PASSED
- ✅ Project structure documented with real directories
- ⏳ Research document (`research.md`) - To be generated by Phase 0 research agents
- ⏳ Data model (`data-model.md`) - To be generated by Phase 1 design
- ⏳ Deployment contracts (`contracts/`) - To be generated by Phase 1 design
- ⏳ Quickstart guide (`quickstart.md`) - To be generated by Phase 1 design

**Next Steps**:
1. Execute Phase 0 research tasks (Docker/K8s/Helm best practices, AI tool patterns)
2. Generate `research.md` with consolidated findings
3. Execute Phase 1 design (create data-model.md, contracts/, quickstart.md)
4. Update agent context with new technology information
5. Re-validate constitution check post-design
6. Proceed to `/sp.tasks` to generate actionable task breakdown

**Branch**: `001-k8s-deployment`
**Plan File**: `D:/q_4/ai-hackathon/phase-4/specs/001-k8s-deployment/plan.md`

**Constitution Compliance**: ✅ VERIFIED - All four core principles and all architectural, security, quality, and workflow constraints are satisfied by this implementation plan.
